{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset shape: (307511, 1422)\n",
      "test dataset shape: (48744, 1421)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"C:/Users/manas/train_final.csv\")\n",
    "print('training dataset shape:', train.shape)\n",
    "#print(app_train.columns)\n",
    "test = pd.read_csv(\"C:/Users/manas/test_final.csv\")\n",
    "print('test dataset shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1421) (48744, 1421)\n"
     ]
    }
   ],
   "source": [
    "## substitute missing value with imputer then scaling with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "train_labels = train['TARGET']\n",
    "train = train.drop(columns=['TARGET'])\n",
    "features = list(train.columns)\n",
    "test = test.copy()\n",
    "imputer = Imputer(strategy='median')\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "imputer.fit(train)\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(test)\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>NAME_TYPE_SUITE_Children</th>\n",
       "      <th>NAME_TYPE_SUITE_Family</th>\n",
       "      <th>NAME_TYPE_SUITE_Group of people</th>\n",
       "      <th>NAME_TYPE_SUITE_Other_A</th>\n",
       "      <th>NAME_TYPE_SUITE_Other_B</th>\n",
       "      <th>NAME_TYPE_SUITE_Spouse, partner</th>\n",
       "      <th>NAME_TYPE_SUITE_Unaccompanied</th>\n",
       "      <th>NAME_INCOME_TYPE_Businessman</th>\n",
       "      <th>...</th>\n",
       "      <th>EXT_SOURCE_2^3</th>\n",
       "      <th>EXT_SOURCE_2^2 EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_2^2 DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_2 EXT_SOURCE_3^2</th>\n",
       "      <th>EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_2 DAYS_BIRTH^2</th>\n",
       "      <th>EXT_SOURCE_3^3</th>\n",
       "      <th>EXT_SOURCE_3^2 DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_3 DAYS_BIRTH^2</th>\n",
       "      <th>DAYS_BIRTH^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626563</td>\n",
       "      <td>0.541836</td>\n",
       "      <td>0.974037</td>\n",
       "      <td>0.541837</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.575199</td>\n",
       "      <td>0.583191</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.551953</td>\n",
       "      <td>0.972706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763635</td>\n",
       "      <td>0.328873</td>\n",
       "      <td>0.742370</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>0.778853</td>\n",
       "      <td>0.707433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335487</td>\n",
       "      <td>0.302298</td>\n",
       "      <td>0.725543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721095</td>\n",
       "      <td>0.657662</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>0.698595</td>\n",
       "      <td>0.373740</td>\n",
       "      <td>0.730817</td>\n",
       "      <td>0.807472</td>\n",
       "      <td>0.598178</td>\n",
       "      <td>0.766427</td>\n",
       "      <td>0.585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784717</td>\n",
       "      <td>0.309615</td>\n",
       "      <td>0.680881</td>\n",
       "      <td>0.889726</td>\n",
       "      <td>0.821909</td>\n",
       "      <td>0.759889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>0.234152</td>\n",
       "      <td>0.587909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636062</td>\n",
       "      <td>0.480765</td>\n",
       "      <td>0.917601</td>\n",
       "      <td>0.713067</td>\n",
       "      <td>0.689623</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209957</td>\n",
       "      <td>0.203454</td>\n",
       "      <td>0.520494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODE_GENDER_F  CODE_GENDER_M  NAME_TYPE_SUITE_Children  \\\n",
       "0            0.0            1.0                       0.0   \n",
       "1            1.0            0.0                       0.0   \n",
       "2            0.0            1.0                       0.0   \n",
       "3            1.0            0.0                       0.0   \n",
       "4            0.0            1.0                       0.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Family  NAME_TYPE_SUITE_Group of people  \\\n",
       "0                     0.0                              0.0   \n",
       "1                     1.0                              0.0   \n",
       "2                     0.0                              0.0   \n",
       "3                     0.0                              0.0   \n",
       "4                     0.0                              0.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Other_A  NAME_TYPE_SUITE_Other_B  \\\n",
       "0                      0.0                      0.0   \n",
       "1                      0.0                      0.0   \n",
       "2                      0.0                      0.0   \n",
       "3                      0.0                      0.0   \n",
       "4                      0.0                      0.0   \n",
       "\n",
       "   NAME_TYPE_SUITE_Spouse, partner  NAME_TYPE_SUITE_Unaccompanied  \\\n",
       "0                              0.0                            1.0   \n",
       "1                              0.0                            0.0   \n",
       "2                              0.0                            1.0   \n",
       "3                              0.0                            1.0   \n",
       "4                              0.0                            1.0   \n",
       "\n",
       "   NAME_INCOME_TYPE_Businessman      ...       EXT_SOURCE_2^3  \\\n",
       "0                           0.0      ...             0.626563   \n",
       "1                           0.0      ...             0.763635   \n",
       "2                           0.0      ...             0.721095   \n",
       "3                           0.0      ...             0.784717   \n",
       "4                           0.0      ...             0.636062   \n",
       "\n",
       "   EXT_SOURCE_2^2 EXT_SOURCE_3  EXT_SOURCE_2^2 DAYS_BIRTH  \\\n",
       "0                     0.541836                   0.974037   \n",
       "1                     0.328873                   0.742370   \n",
       "2                     0.657662                   0.766394   \n",
       "3                     0.309615                   0.680881   \n",
       "4                     0.480765                   0.917601   \n",
       "\n",
       "   EXT_SOURCE_2 EXT_SOURCE_3^2  EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH  \\\n",
       "0                     0.541837                              0.538356   \n",
       "1                     0.874526                              0.778853   \n",
       "2                     0.698595                              0.373740   \n",
       "3                     0.889726                              0.821909   \n",
       "4                     0.713067                              0.689623   \n",
       "\n",
       "   EXT_SOURCE_2 DAYS_BIRTH^2  EXT_SOURCE_3^3  EXT_SOURCE_3^2 DAYS_BIRTH  \\\n",
       "0                   0.575199        0.583191                   0.992715   \n",
       "1                   0.707433        0.000000                   0.335487   \n",
       "2                   0.730817        0.807472                   0.598178   \n",
       "3                   0.759889        0.000000                   0.246700   \n",
       "4                   0.666656        0.000000                   0.209957   \n",
       "\n",
       "   EXT_SOURCE_3 DAYS_BIRTH^2  DAYS_BIRTH^3  \n",
       "0                   0.551953      0.972706  \n",
       "1                   0.302298      0.725543  \n",
       "2                   0.766427      0.585062  \n",
       "3                   0.234152      0.587909  \n",
       "4                   0.203454      0.520494  \n",
       "\n",
       "[5 rows x 1421 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(train, columns = features)\n",
    "test = pd.DataFrame(test, columns = features)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('C:/Users/manas/Desktop/Springboard/Capstone ideas/Home credit default risk/Data/application_train.csv')\n",
    "app_test = pd.read_csv('C:/Users/manas/Desktop/Springboard/Capstone ideas/Home credit default risk/Data/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset shape: (307511, 1421)\n",
      "test dataset shape: (48744, 1421)\n"
     ]
    }
   ],
   "source": [
    "train['SK_ID_CURR'] = app_train['SK_ID_CURR']\n",
    "test['SK_ID_CURR'] = app_test['SK_ID_CURR']\n",
    "print('training dataset shape:', train.shape)\n",
    "print('test dataset shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is ready to be used for model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## LightGBM\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "def model(features, train_labels, test_features, n_folds = 5):\n",
    "    \n",
    "       \n",
    "    # Extract the ids\n",
    "    train_id = features['SK_ID_CURR']\n",
    "    test_id = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = train_labels\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'],\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 1420)\n",
      "Testing Data Shape:  (48744, 1420)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.783442\tvalid's binary_logloss: 0.531643\ttrain's auc: 0.83227\ttrain's binary_logloss: 0.518788\n",
      "[400]\tvalid's auc: 0.78479\tvalid's binary_logloss: 0.504649\ttrain's auc: 0.86956\ttrain's binary_logloss: 0.480325\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid's auc: 0.784974\tvalid's binary_logloss: 0.503182\ttrain's auc: 0.871454\ttrain's binary_logloss: 0.478251\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.780963\tvalid's binary_logloss: 0.533257\ttrain's auc: 0.832822\ttrain's binary_logloss: 0.518454\n",
      "[400]\tvalid's auc: 0.7825\tvalid's binary_logloss: 0.50689\ttrain's auc: 0.869646\ttrain's binary_logloss: 0.480099\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid's auc: 0.782789\tvalid's binary_logloss: 0.515675\ttrain's auc: 0.857538\ttrain's binary_logloss: 0.493221\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.787118\tvalid's binary_logloss: 0.533434\ttrain's auc: 0.832304\ttrain's binary_logloss: 0.519585\n",
      "[400]\tvalid's auc: 0.788395\tvalid's binary_logloss: 0.506433\ttrain's auc: 0.869447\ttrain's binary_logloss: 0.480752\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid's auc: 0.788696\tvalid's binary_logloss: 0.513326\ttrain's auc: 0.860049\ttrain's binary_logloss: 0.490887\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.786932\tvalid's binary_logloss: 0.531112\ttrain's auc: 0.832345\ttrain's binary_logloss: 0.519117\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid's auc: 0.787398\tvalid's binary_logloss: 0.521811\ttrain's auc: 0.84582\ttrain's binary_logloss: 0.505551\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.781891\tvalid's binary_logloss: 0.534303\ttrain's auc: 0.833404\ttrain's binary_logloss: 0.518131\n",
      "[400]\tvalid's auc: 0.782609\tvalid's binary_logloss: 0.508184\ttrain's auc: 0.870731\ttrain's binary_logloss: 0.479326\n",
      "Early stopping, best iteration is:\n",
      "[300]\tvalid's auc: 0.783191\tvalid's binary_logloss: 0.520076\ttrain's auc: 0.853669\ttrain's binary_logloss: 0.497436\n",
      "      fold     train     valid\n",
      "0        0  0.871454  0.784974\n",
      "1        1  0.857538  0.782789\n",
      "2        2  0.860049  0.788696\n",
      "3        3  0.845820  0.787398\n",
      "4        4  0.853669  0.783191\n",
      "5  overall  0.857706  0.785376\n"
     ]
    }
   ],
   "source": [
    "submission, fi, metrics = model(train, train_labels, test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A thorough cleaning and inclusion of other tables has improved the score from 0.7657 to 0.7853."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1383</td>\n",
       "      <td>CREDIT_TERM</td>\n",
       "      <td>334.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1307</td>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>164.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>client_installments_AMT_PAYMENT_min_sum</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1323</td>\n",
       "      <td>EXT_SOURCE_1_x</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306</td>\n",
       "      <td>AMT_CREDIT</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                  feature  importance\n",
       "0   1383                              CREDIT_TERM       334.4\n",
       "1   1307                              AMT_ANNUITY       164.8\n",
       "2   1294  client_installments_AMT_PAYMENT_min_sum       142.0\n",
       "3   1323                           EXT_SOURCE_1_x       114.0\n",
       "4   1306                               AMT_CREDIT        99.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_sorted = fi.sort_values('importance', ascending=False).reset_index()\n",
    "fi_sorted.head() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
